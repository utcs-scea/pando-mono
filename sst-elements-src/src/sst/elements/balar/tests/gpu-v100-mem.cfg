#For V100, we have 4 HBM stack, each with 8 channels, so total we have 32 memory parts
[GPU]
clock: 1447MHz
gpu_cores: 80
gpu_l2_parts: 32
gpu_l2_capacity: 192KiB
#we assume PCIE with 16GB/Sec. Each cycle, we transfer a 4KB page, thus latency = 4/(16*1024*1024) = 23840ps
gpu_cpu_latency: 23840ps
#this is not used for now
gpu_cpu_bandwidth: 16GB/s

[GPUMemory]
clock: 877MHz
#network_bw per mem_part. this should be equal to the actual mem_bw. So, total mem BW = gpu_mem_parts*network_bw = 1 TB/S (in Volta V100, it is 900 GB/Sec, so very close)
network_bw: 32GB/s
#this is the total capacity of all gpu_mem_parts. This should be in MiB.
capacity: 16384MiB
memControllers: 2
hbmStacks: 4
hbmChan: 4
hbmRows: 16384

[GPUNetwork]
#1200MHz time period plus slack for xbar latency
frequency: 1200MHz
buffer_depth: 128
input_ports: 3
output_ports: 3

latency: 750ps
#total BW
bandwidth: 4800GB/s
#BW per xbar link
linkbandwidth: 37.5GB/s
flit_size: 40B
